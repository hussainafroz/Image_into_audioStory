{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hussain Afroz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import hf_hub_download\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMG TO TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hussain Afroz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arafed image of a man with a beard and a suit\n"
     ]
    }
   ],
   "source": [
    "#img2text\n",
    "def img2text(url):\n",
    "    image_to_text = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-large\") #pipeline(task , model)\n",
    "    text = image_to_text(\n",
    "         url)[0]['generated_text'] #['generated_text'] #only to take the text generated\n",
    "    print(text)\n",
    "    return text\n",
    "scenario = img2text(\"img.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LLM (TEXT TO STORY TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arafed image of a man with a beard and a suit in hand. Another figure with red colored skin looked down at it, making it seem as though an enemy had already been slain upon the throne that held out to attack him by his name!  stack on each one again until he was standing alone; no weapons displayed at all were visible behind the curtain-like doors as if there is\n"
     ]
    }
   ],
   "source": [
    "##llm\n",
    "from transformers import pipeline, TextGenerationPipeline, GPT2LMHeadModel, AutoTokenizer\n",
    "# model_name = \"aspis/gpt2-genre-story-generation\"\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# generator = TextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
    "# input_prompt = scenario\n",
    "# story = generator(input_prompt, max_length=80, do_sample=True,repetition_penalty=1.5, temperature=1.2, \n",
    "#                top_p=0.95, top_k=50)\n",
    "# print(story)\n",
    "\n",
    "def generate_story(scenario):\n",
    "        model_name = \"aspis/gpt2-genre-story-generation\"\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        generator = TextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
    "        input_prompt = scenario\n",
    "        story = generator(input_prompt, max_length=80, do_sample=True,repetition_penalty=1.5, temperature=1.2, \n",
    "                    top_p=0.95, top_k=50)\n",
    "        #print(story[0]['generated_text'])\n",
    "        return story[0]['generated_text']\n",
    "story = generate_story(scenario)\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT TO SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def text2speech(story):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/espnet/kan-bayashi_ljspeech_vits\"\n",
    "    headers = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    payloads = {\n",
    "        \"inputs\": story  # Wrap the message in a list to create a JSON-serializable structure\n",
    "    }\n",
    "\n",
    "    res = requests.post(API_URL, headers=headers, json=payloads)\n",
    "    \n",
    "    if res.status_code == 200:\n",
    "        with open('audio.flac', 'wb') as file:\n",
    "            file.write(res.content)\n",
    "        print(\"Audio file saved successfully.\")\n",
    "    else:\n",
    "        print(\"Error:\", res.text)\n",
    "text2speech(story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
